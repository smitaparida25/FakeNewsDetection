{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec83b42-c603-4dee-8d3e-5aebc7b5188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n",
      "label\n",
      "2    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# df = dataframe\n",
    "# ../ moves up one level, from notebook to FakeNewsDetection\n",
    "df_true = pd.read_csv(\"../data/True.csv\")\n",
    "df_fake = pd.read_csv(\"../data/Fake.csv\")\n",
    "\n",
    "df_true.head(),\n",
    "df_fake.head()\n",
    "df_true[\"label\"] = 1\n",
    "df_fake[\"label\"] = 2\n",
    "\n",
    "df = pd.concat([df_true, df_fake], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df.columns)\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84bceff-2b65-429a-9d29-78dabce422fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label'], dtype='object')\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  donald trump white house chaos trying cover ru...      2\n",
      "1  donald trump presumptive gop nominee time reme...      2\n",
      "2  mike penny huge homophobe support exgay conver...      2\n",
      "3  san francisco reuters california attorney gene...      1\n",
      "4  twisted reasoning come pelosi day especially 2...      2\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# remove unnecessary columns\n",
    "df = df[[\"text\",\"label\"]]\n",
    "print(df.columns)\n",
    "\n",
    "# drop missing values\n",
    "print(df.isnull().sum())\n",
    "#if there's missing value -> df = df.dropna()\n",
    "\n",
    "# Lowercasing\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "# Removing Punctuation\n",
    "df[\"text\"] =  df[\"text\"].str.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "#remove stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "# making a set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['text'] = df['text'].apply(lambda x : ' '.join(lemmatizer.lemmatize(word) for word in x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a9eb429-66fe-4fc0-9821-97f09fb1c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  donald trump white house chaos trying cover ru...      2\n",
      "1  donald trump presumptive gop nominee time reme...      2\n",
      "2  mike penny huge homophobe support exgay conver...      2\n",
      "3  san francisco reuters california attorney gene...      1\n",
      "4  twisted reasoning come pelosi day especially 2...      2\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71241f1-e9ac-4a4d-b5ee-5b876389b2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
